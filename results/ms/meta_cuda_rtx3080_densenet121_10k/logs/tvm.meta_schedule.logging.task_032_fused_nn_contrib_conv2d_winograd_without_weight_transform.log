2024-03-20 22:52:31 [INFO] [task_scheduler.cc:160] Initializing Task #32: "fused_nn_contrib_conv2d_winograd_without_weight_transform"
2024-03-20 22:52:31 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(128), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(32)), "float32"), conv2d_winograd: T.Buffer((T.int64(1), T.int64(32), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(9), T.int64(9)))
        input_tile = T.alloc_buffer((T.int64(128), T.int64(16), T.int64(4), T.int64(4)))
        B = T.alloc_buffer((T.int64(4), T.int64(4)))
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(32), T.int64(16)))
        A = T.alloc_buffer((T.int64(4), T.int64(2)))
        inverse = T.alloc_buffer((T.int64(32), T.int64(16), T.int64(2), T.int64(2)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(128), T.int64(9), T.int64(9)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3])
                data_pad[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for ci, p, eps, nu in T.grid(T.int64(128), T.int64(16), T.int64(4), T.int64(4)):
            with T.block("input_tile"):
                v_ci, v_p, v_eps, v_nu = T.axis.remap("SSSS", [ci, p, eps, nu])
                T.reads(data_pad[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps, v_p % T.int64(4) * T.int64(2) + v_nu])
                T.writes(input_tile[v_ci, v_p, v_eps, v_nu])
                T.block_attr({"schedule_rule": "None"})
                input_tile[v_ci, v_p, v_eps, v_nu] = data_pad[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps, v_p % T.int64(4) * T.int64(2) + v_nu]
        for i, j in T.grid(T.int64(4), T.int64(4)):
            with T.block("B"):
                v_i, v_j = T.axis.remap("SS", [i, j])
                T.reads()
                T.writes(B[v_i, v_j])
                T.block_attr({"schedule_rule": "None"})
                B[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
        for eps, nu, ci, p, r_a, r_b in T.grid(T.int64(4), T.int64(4), T.int64(128), T.int64(16), T.int64(4), T.int64(4)):
            with T.block("data_pack"):
                v_eps, v_nu, v_ci, v_p, v_r_a, v_r_b = T.axis.remap("SSSSRR", [eps, nu, ci, p, r_a, r_b])
                T.reads(input_tile[v_ci, v_p, v_r_a, v_r_b], B[T.min(v_r_a, v_r_b):T.min(v_r_a, v_r_b) + (T.max(v_r_a, v_r_b) + T.int64(1) - T.min(v_r_a, v_r_b)), T.min(v_eps, v_nu):T.min(v_eps, v_nu) + (T.max(v_eps, v_nu) + T.int64(1) - T.min(v_eps, v_nu))])
                T.writes(data_pack[v_eps, v_nu, v_ci, v_p])
                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                with T.init():
                    data_pack[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                data_pack[v_eps, v_nu, v_ci, v_p] = data_pack[v_eps, v_nu, v_ci, v_p] + input_tile[v_ci, v_p, v_r_a, v_r_b] * B[v_r_a, v_eps] * B[v_r_b, v_nu]
        for eps, nu, co, p, ci in T.grid(T.int64(4), T.int64(4), T.int64(32), T.int64(16), T.int64(128)):
            with T.block("bgemm"):
                v_eps, v_nu, v_co, v_p, v_ci = T.axis.remap("SSSSR", [eps, nu, co, p, ci])
                T.reads(data_pack[v_eps, v_nu, v_ci, v_p], p1[v_eps, v_nu, v_ci, v_co])
                T.writes(bgemm[v_eps, v_nu, v_co, v_p])
                with T.init():
                    bgemm[v_eps, v_nu, v_co, v_p] = T.float32(0)
                bgemm[v_eps, v_nu, v_co, v_p] = bgemm[v_eps, v_nu, v_co, v_p] + data_pack[v_eps, v_nu, v_ci, v_p] * p1[v_eps, v_nu, v_ci, v_co]
        for i, j in T.grid(T.int64(4), T.int64(2)):
            with T.block("A"):
                v_i, v_j = T.axis.remap("SS", [i, j])
                T.reads()
                T.writes(A[v_i, v_j])
                T.block_attr({"schedule_rule": "None"})
                A[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
        for co, p, vh, vw, r_a, r_b in T.grid(T.int64(32), T.int64(16), T.int64(2), T.int64(2), T.int64(4), T.int64(4)):
            with T.block("inverse"):
                v_co, v_p, v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSSSRR", [co, p, vh, vw, r_a, r_b])
                T.reads(bgemm[v_r_a, v_r_b, v_co, v_p], A[T.min(v_r_a, v_r_b):T.min(v_r_a, v_r_b) + (T.max(v_r_a, v_r_b) + T.int64(1) - T.min(v_r_a, v_r_b)), T.min(v_vh, v_vw):T.min(v_vh, v_vw) + (T.max(v_vh, v_vw) + T.int64(1) - T.min(v_vh, v_vw))])
                T.writes(inverse[v_co, v_p, v_vh, v_vw])
                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                with T.init():
                    inverse[v_co, v_p, v_vh, v_vw] = T.float32(0)
                inverse[v_co, v_p, v_vh, v_vw] = inverse[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * A[v_r_a, v_vh] * A[v_r_b, v_vw]
        for n, co, h, w in T.grid(T.int64(1), T.int64(32), T.int64(7), T.int64(7)):
            with T.block("conv2d_winograd"):
                v_n, v_co, v_h, v_w = T.axis.remap("SSSS", [n, co, h, w])
                T.reads(inverse[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)])
                T.writes(conv2d_winograd[v_n, v_co, v_h, v_w])
                conv2d_winograd[v_n, v_co, v_h, v_w] = inverse[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)]
2024-03-20 22:52:31 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-03-20 22:52:31 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(128), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(32)), "float32"), conv2d_winograd: T.Buffer((T.int64(1), T.int64(32), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 64})
            input_tile_local = T.alloc_buffer((T.int64(128), T.int64(16), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(16)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(32), T.int64(16)))
            inverse_local = T.alloc_buffer((T.int64(32), T.int64(16), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(16)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(32), T.int64(16)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(16)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(32)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(128), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                            v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(128), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                        v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(128), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(4), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                        for ci_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(2048)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused)
                                    v2 = T.axis.spatial(T.int64(128), ci_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused % T.int64(512) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(16), ax0_ax1_ax2_ax3_fused % T.int64(16))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(4096)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(1024))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused)
                                    v2 = T.axis.spatial(T.int64(128), ci_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused % T.int64(1024) // T.int64(32))
                                    v3 = T.axis.spatial(T.int64(32), ax0_ax1_ax2_ax3_fused % T.int64(32))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(4) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused + nu_3 + nu_4)
                                    v_co = T.axis.spatial(T.int64(32), eps_1_nu_1_co_1_p_1_fused * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) + co_3 + co_4)
                                    v_p = T.axis.spatial(T.int64(16), p_3 + p_4)
                                    v_ci = T.axis.reduce(T.int64(128), ci_0 * T.int64(32) + ci_1 * T.int64(4) + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(16)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(4) * T.int64(2) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused + ax1)
                                v2 = T.axis.spatial(T.int64(32), eps_1_nu_1_co_1_p_1_fused * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) + ax2)
                                v3 = T.axis.spatial(T.int64(16), ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(32), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                            v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(32), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(16))
                            v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                            T.where((n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                            T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)])
                            T.writes(conv2d_winograd[v_n, v_co, v_h, v_w])
                            conv2d_winograd[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
b5, b6 = sch.get_producers(block=b2)
sch.compute_inline(block=b6)
b7, = sch.get_consumers(block=b2)
l8, l9, l10, l11 = sch.get_loops(block=b7)
l12, l13 = sch.split(loop=l10, factors=[None, 2], preserve_unit_iters=True)
l14, l15 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l12, l14, l13, l15)
sch.compute_at(block=b2, loop=l14, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l16, l17, l18, l19, l20, l21, l22, l23, l24, l25 = sch.get_loops(block=b2)
sch.unroll(loop=l22)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
b26, b27 = sch.get_producers(block=b0)
sch.compute_inline(block=b27)
b28, = sch.get_producers(block=b26)
l29, l30, l31, l32, l33, l34 = sch.get_loops(block=b0)
sch.reorder(l31, l32, l29, l30, l33, l34)
sch.unroll(loop=l29)
sch.unroll(loop=l30)
sch.unroll(loop=l33)
sch.unroll(loop=l34)
l35 = sch.fuse(l31, l32, preserve_unit_iters=True)
v36 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l37, l38 = sch.split(loop=l35, factors=[None, v36], preserve_unit_iters=True)
sch.bind(loop=l37, thread_axis="blockIdx.x")
sch.bind(loop=l38, thread_axis="threadIdx.x")
b39 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b39, loop=l38, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b26, loop=l38, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b26, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b28)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l40, l41, l42, l43, l44 = sch.get_loops(block=b1)
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l40, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l40, factors=[v45, v46, v47, v48, v49], preserve_unit_iters=True)
v55, v56, v57, v58, v59 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l60, l61, l62, l63, l64 = sch.split(loop=l41, factors=[v55, v56, v57, v58, v59], preserve_unit_iters=True)
v65, v66, v67, v68, v69 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 8, 4, 1, 1])
l70, l71, l72, l73, l74 = sch.split(loop=l42, factors=[v65, v66, v67, v68, v69], preserve_unit_iters=True)
v75, v76, v77, v78, v79 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 1, 16, 1])
l80, l81, l82, l83, l84 = sch.split(loop=l43, factors=[v75, v76, v77, v78, v79], preserve_unit_iters=True)
v85, v86, v87 = sch.sample_perfect_tile(loop=l44, n=3, max_innermost_factor=64, decision=[4, 8, 4])
l88, l89, l90 = sch.split(loop=l44, factors=[v85, v86, v87], preserve_unit_iters=True)
sch.reorder(l50, l60, l70, l80, l51, l61, l71, l81, l52, l62, l72, l82, l88, l89, l53, l63, l73, l83, l90, l54, l64, l74, l84)
l91 = sch.fuse(l50, l60, l70, l80, preserve_unit_iters=True)
sch.bind(loop=l91, thread_axis="blockIdx.x")
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="vthread.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b94 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b94, loop=l93, preserve_unit_loops=True, index=-1)
b95 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b95, loop=l88, preserve_unit_loops=True, index=-1)
l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b95)
l104 = sch.fuse(l100, l101, l102, l103, preserve_unit_iters=True)
v105 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b95, ann_key="meta_schedule.cooperative_fetch", ann_val=v105)
b106 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b106, loop=l88, preserve_unit_loops=True, index=-1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b106)
l115 = sch.fuse(l111, l112, l113, l114, preserve_unit_iters=True)
v116 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b106, ann_key="meta_schedule.cooperative_fetch", ann_val=v116)
v117 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v117)
l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b3)
l124 = sch.fuse(l118, l119, l120, l121, preserve_unit_iters=True)
v125 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
l126, l127 = sch.split(loop=l124, factors=[None, v125], preserve_unit_iters=True)
sch.bind(loop=l126, thread_axis="blockIdx.x")
sch.bind(loop=l127, thread_axis="threadIdx.x")
2024-03-20 22:52:31 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(128), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(32)), "float32"), conv2d_winograd: T.Buffer((T.int64(1), T.int64(32), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 16})
            input_tile_local = T.alloc_buffer((T.int64(128), T.int64(16), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(16)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(32), T.int64(16)))
            inverse_local = T.alloc_buffer((T.int64(32), T.int64(16), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(16)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(32), T.int64(16)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(16)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(32)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(128), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                            v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(128), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                        v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(128), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(4), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                        for ci_0_fused in T.serial(T.int64(4), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(2048)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused)
                                    v2 = T.axis.spatial(T.int64(128), ci_0_fused * T.int64(32) + ax0_ax1_ax2_ax3_fused % T.int64(512) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(16), ax0_ax1_ax2_ax3_fused % T.int64(16))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(4096)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(1024))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused)
                                    v2 = T.axis.spatial(T.int64(128), ci_0_fused * T.int64(32) + ax0_ax1_ax2_ax3_fused % T.int64(1024) // T.int64(32))
                                    v3 = T.axis.spatial(T.int64(32), ax0_ax1_ax2_ax3_fused % T.int64(32))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(4) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused + nu_3 + nu_4)
                                    v_co = T.axis.spatial(T.int64(32), eps_1_nu_1_co_1_p_1_fused * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) + co_3 + co_4)
                                    v_p = T.axis.spatial(T.int64(16), p_3 + p_4)
                                    v_ci = T.axis.reduce(T.int64(128), ci_0_fused * T.int64(32) + ci_1 * T.int64(4) + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(16)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(4) * T.int64(2) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused + ax1)
                                v2 = T.axis.spatial(T.int64(32), eps_1_nu_1_co_1_p_1_fused * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) + ax2)
                                v3 = T.axis.spatial(T.int64(16), ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(32), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                            v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(32), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16))
                            v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                            T.where((n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                            T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)])
                            T.writes(conv2d_winograd[v_n, v_co, v_h, v_w])
                            conv2d_winograd[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
b5, b6 = sch.get_producers(block=b2)
sch.compute_inline(block=b6)
b7, = sch.get_consumers(block=b2)
l8, l9, l10, l11 = sch.get_loops(block=b7)
l12, l13 = sch.split(loop=l10, factors=[None, 2], preserve_unit_iters=True)
l14, l15 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l12, l14, l13, l15)
sch.compute_at(block=b2, loop=l14, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l16, l17, l18, l19, l20, l21, l22, l23, l24, l25 = sch.get_loops(block=b2)
sch.unroll(loop=l22)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
b26, b27 = sch.get_producers(block=b0)
sch.compute_inline(block=b27)
b28, = sch.get_producers(block=b26)
l29, l30, l31, l32, l33, l34 = sch.get_loops(block=b0)
sch.reorder(l31, l32, l29, l30, l33, l34)
sch.unroll(loop=l29)
sch.unroll(loop=l30)
sch.unroll(loop=l33)
sch.unroll(loop=l34)
l35 = sch.fuse(l31, l32, preserve_unit_iters=True)
v36 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l37, l38 = sch.split(loop=l35, factors=[None, v36], preserve_unit_iters=True)
sch.bind(loop=l37, thread_axis="blockIdx.x")
sch.bind(loop=l38, thread_axis="threadIdx.x")
b39 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b39, loop=l38, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b26, loop=l38, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b26, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b28)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l40, l41, l42, l43, l44 = sch.get_loops(block=b1)
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l40, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l40, factors=[v45, v46, v47, v48, v49], preserve_unit_iters=True)
v55, v56, v57, v58, v59 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l60, l61, l62, l63, l64 = sch.split(loop=l41, factors=[v55, v56, v57, v58, v59], preserve_unit_iters=True)
v65, v66, v67, v68, v69 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 8, 4, 1, 1])
l70, l71, l72, l73, l74 = sch.split(loop=l42, factors=[v65, v66, v67, v68, v69], preserve_unit_iters=True)
v75, v76, v77, v78, v79 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 1, 16, 1])
l80, l81, l82, l83, l84 = sch.split(loop=l43, factors=[v75, v76, v77, v78, v79], preserve_unit_iters=True)
v85, v86, v87 = sch.sample_perfect_tile(loop=l44, n=3, max_innermost_factor=64, decision=[4, 8, 4])
l88, l89, l90 = sch.split(loop=l44, factors=[v85, v86, v87], preserve_unit_iters=True)
sch.reorder(l50, l60, l70, l80, l51, l61, l71, l81, l52, l62, l72, l82, l88, l89, l53, l63, l73, l83, l90, l54, l64, l74, l84)
l91 = sch.fuse(l50, l60, l70, l80, preserve_unit_iters=True)
sch.bind(loop=l91, thread_axis="blockIdx.x")
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="vthread.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b94 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b94, loop=l93, preserve_unit_loops=True, index=-1)
b95 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b95, loop=l88, preserve_unit_loops=True, index=-1)
l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b95)
l104 = sch.fuse(l100, l101, l102, l103, preserve_unit_iters=True)
v105 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b95, ann_key="meta_schedule.cooperative_fetch", ann_val=v105)
b106 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b106, loop=l88, preserve_unit_loops=True, index=-1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b106)
l115 = sch.fuse(l111, l112, l113, l114, preserve_unit_iters=True)
v116 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b106, ann_key="meta_schedule.cooperative_fetch", ann_val=v116)
l117 = sch.fuse(l88, preserve_unit_iters=True)
sch.annotate(block_or_loop=l117, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l117, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l117, ann_key="software_pipeline_async_stages", ann_val=[0])
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
2024-03-20 22:52:31 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(128), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(32)), "float32"), conv2d_winograd: T.Buffer((T.int64(1), T.int64(32), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            input_tile_local = T.alloc_buffer((T.int64(128), T.int64(16), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(16)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(32), T.int64(16)))
            inverse_local = T.alloc_buffer((T.int64(32), T.int64(16), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(16)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(32), T.int64(16)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(16)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(128), T.int64(32)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(128), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                            v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(128), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                        v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(128), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(4), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                        for ci_0_fused in T.serial(T.int64(4), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(2048)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused)
                                    v2 = T.axis.spatial(T.int64(128), ci_0_fused * T.int64(32) + ax0_ax1_ax2_ax3_fused % T.int64(512) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(16), ax0_ax1_ax2_ax3_fused % T.int64(16))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(4096)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(1024))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused)
                                    v2 = T.axis.spatial(T.int64(128), ci_0_fused * T.int64(32) + ax0_ax1_ax2_ax3_fused % T.int64(1024) // T.int64(32))
                                    v3 = T.axis.spatial(T.int64(32), ax0_ax1_ax2_ax3_fused % T.int64(32))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(4) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused + nu_3 + nu_4)
                                    v_co = T.axis.spatial(T.int64(32), eps_1_nu_1_co_1_p_1_fused * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) + co_3 + co_4)
                                    v_p = T.axis.spatial(T.int64(16), p_3 + p_4)
                                    v_ci = T.axis.reduce(T.int64(128), ci_0_fused * T.int64(32) + ci_1 * T.int64(4) + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(16)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(4) * T.int64(2) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused + ax1)
                                v2 = T.axis.spatial(T.int64(32), eps_1_nu_1_co_1_p_1_fused * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) + ax2)
                                v3 = T.axis.spatial(T.int64(16), ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(32), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                            v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(32), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                            v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                            T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                            T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)])
                            T.writes(conv2d_winograd[v_n, v_co, v_h, v_w])
                            conv2d_winograd[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
b5, b6 = sch.get_producers(block=b2)
sch.compute_inline(block=b6)
b7, = sch.get_consumers(block=b2)
l8, l9, l10, l11 = sch.get_loops(block=b7)
l12, l13 = sch.split(loop=l10, factors=[None, 2], preserve_unit_iters=True)
l14, l15 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l12, l14, l13, l15)
sch.compute_at(block=b2, loop=l14, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l16, l17, l18, l19, l20, l21, l22, l23, l24, l25 = sch.get_loops(block=b2)
sch.unroll(loop=l22)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
b26, b27 = sch.get_producers(block=b0)
sch.compute_inline(block=b27)
b28, = sch.get_producers(block=b26)
l29, l30, l31, l32, l33, l34 = sch.get_loops(block=b0)
sch.reorder(l31, l32, l29, l30, l33, l34)
sch.unroll(loop=l29)
sch.unroll(loop=l30)
sch.unroll(loop=l33)
sch.unroll(loop=l34)
l35 = sch.fuse(l31, l32, preserve_unit_iters=True)
v36 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l37, l38 = sch.split(loop=l35, factors=[None, v36], preserve_unit_iters=True)
sch.bind(loop=l37, thread_axis="blockIdx.x")
sch.bind(loop=l38, thread_axis="threadIdx.x")
b39 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b39, loop=l38, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b26, loop=l38, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b26, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b28)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l40, l41, l42, l43, l44 = sch.get_loops(block=b1)
v45, v46, v47, v48, v49 = sch.sample_perfect_tile(loop=l40, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l50, l51, l52, l53, l54 = sch.split(loop=l40, factors=[v45, v46, v47, v48, v49], preserve_unit_iters=True)
v55, v56, v57, v58, v59 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l60, l61, l62, l63, l64 = sch.split(loop=l41, factors=[v55, v56, v57, v58, v59], preserve_unit_iters=True)
v65, v66, v67, v68, v69 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 8, 4, 1, 1])
l70, l71, l72, l73, l74 = sch.split(loop=l42, factors=[v65, v66, v67, v68, v69], preserve_unit_iters=True)
v75, v76, v77, v78, v79 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 1, 16, 1])
l80, l81, l82, l83, l84 = sch.split(loop=l43, factors=[v75, v76, v77, v78, v79], preserve_unit_iters=True)
v85, v86, v87 = sch.sample_perfect_tile(loop=l44, n=3, max_innermost_factor=64, decision=[4, 8, 4])
l88, l89, l90 = sch.split(loop=l44, factors=[v85, v86, v87], preserve_unit_iters=True)
sch.reorder(l50, l60, l70, l80, l51, l61, l71, l81, l52, l62, l72, l82, l88, l89, l53, l63, l73, l83, l90, l54, l64, l74, l84)
l91 = sch.fuse(l50, l60, l70, l80, preserve_unit_iters=True)
sch.bind(loop=l91, thread_axis="blockIdx.x")
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="vthread.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b94 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b94, loop=l93, preserve_unit_loops=True, index=-1)
b95 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b95, loop=l88, preserve_unit_loops=True, index=-1)
l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b95)
l104 = sch.fuse(l100, l101, l102, l103, preserve_unit_iters=True)
v105 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b95, ann_key="meta_schedule.cooperative_fetch", ann_val=v105)
b106 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b106, loop=l88, preserve_unit_loops=True, index=-1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b106)
l115 = sch.fuse(l111, l112, l113, l114, preserve_unit_iters=True)
v116 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b106, ann_key="meta_schedule.cooperative_fetch", ann_val=v116)
l117 = sch.fuse(l88, preserve_unit_iters=True)
sch.annotate(block_or_loop=l117, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l117, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l117, ann_key="software_pipeline_async_stages", ann_val=[0])
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
2024-03-20 23:05:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-03-20 23:05:38 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-03-20 23:05:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 482 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-20 23:05:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 976 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-20 23:05:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 1459 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-20 23:05:44 [INFO] [evolutionary_search.cc:723] Sampled 77 candidate(s)
2024-03-20 23:05:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 80 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-20 23:05:55 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 70 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-20 23:06:01 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 81 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-20 23:06:07 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 73 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-20 23:06:07 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9992  0.9991  0.9987  0.9986  0.9975  0.9963  0.9949  0.9947  0.9946  0.9928  0.9919  0.9919  0.9915  0.9912  0.9910  0.9910
[17 : 32]:	0.9908  0.9895  0.9887  0.9876  0.9876  0.9873  0.9869  0.9853  0.9847  0.9837  0.9837  0.9824  0.9808  0.9808  0.9802  0.9795
[33 : 48]:	0.9786  0.9773  0.9767  0.9762  0.9749  0.9743  0.9740  0.9731  0.9731  0.9726  0.9718  0.9715  0.9704  0.9700  0.9698  0.9691
[49 : 64]:	0.9682  0.9681  0.9679  0.9672  0.9668  0.9664  0.9655  0.9654  0.9649  0.9645  0.9643  0.9639  0.9639  0.9638  0.9637  0.9635
2024-03-20 23:06:07 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-03-20 23:06:07 [INFO] [evolutionary_search.cc:730] Sending 63 candidates(s) for measurement
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #1: GFLOPs: 179.4443. Time: 20.9999 us. Best GFLOPs: 179.4443
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #2: GFLOPs: 191.5965. Time: 19.6680 us. Best GFLOPs: 191.5965
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #3: GFLOPs: 114.7165. Time: 32.8490 us. Best GFLOPs: 191.5965
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #4: GFLOPs: 124.8908. Time: 30.1729 us. Best GFLOPs: 191.5965
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #5: GFLOPs: 105.2294. Time: 35.8105 us. Best GFLOPs: 191.5965
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #6: GFLOPs: 135.0221. Time: 27.9089 us. Best GFLOPs: 191.5965
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #7: GFLOPs: 146.2474. Time: 25.7667 us. Best GFLOPs: 191.5965
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #8: GFLOPs: 133.3694. Time: 28.2548 us. Best GFLOPs: 191.5965
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #9: GFLOPs: 182.0900. Time: 20.6948 us. Best GFLOPs: 191.5965
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #10: GFLOPs: 149.2785. Time: 25.2436 us. Best GFLOPs: 191.5965
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #11: GFLOPs: 142.3206. Time: 26.4777 us. Best GFLOPs: 191.5965
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #12: GFLOPs: 126.4864. Time: 29.7923 us. Best GFLOPs: 191.5965
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #13: GFLOPs: 29.9344. Time: 125.8858 us. Best GFLOPs: 191.5965
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #14: GFLOPs: 193.3163. Time: 19.4930 us. Best GFLOPs: 193.3163
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #15: GFLOPs: 266.4381. Time: 14.1433 us. Best GFLOPs: 266.4381
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #16: GFLOPs: 68.3221. Time: 55.1552 us. Best GFLOPs: 266.4381
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #17: GFLOPs: 231.3848. Time: 16.2859 us. Best GFLOPs: 266.4381
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #18: GFLOPs: 85.2569. Time: 44.1996 us. Best GFLOPs: 266.4381
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #19: GFLOPs: 80.1311. Time: 47.0270 us. Best GFLOPs: 266.4381
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #20: GFLOPs: 103.4126. Time: 36.4397 us. Best GFLOPs: 266.4381
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #21: GFLOPs: 44.1474. Time: 85.3578 us. Best GFLOPs: 266.4381
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #22: GFLOPs: 131.1729. Time: 28.7279 us. Best GFLOPs: 266.4381
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #23: GFLOPs: 324.5327. Time: 11.6115 us. Best GFLOPs: 324.5327
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #24: GFLOPs: 217.6052. Time: 17.3172 us. Best GFLOPs: 324.5327
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #25: GFLOPs: 434.6353. Time: 8.6701 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #26: GFLOPs: 231.3916. Time: 16.2855 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #27: GFLOPs: 282.4580. Time: 13.3412 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #28: GFLOPs: 291.3023. Time: 12.9361 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #29: GFLOPs: 158.5994. Time: 23.7600 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #30: GFLOPs: 223.5647. Time: 16.8556 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #31: GFLOPs: 292.8821. Time: 12.8663 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #32: GFLOPs: 348.1168. Time: 10.8249 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #33: GFLOPs: 100.4777. Time: 37.5041 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #34: GFLOPs: 88.7446. Time: 42.4625 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #35: GFLOPs: 188.9575. Time: 19.9427 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #36: GFLOPs: 96.3956. Time: 39.0922 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #37: GFLOPs: 324.8507. Time: 11.6002 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #38: GFLOPs: 117.6874. Time: 32.0197 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #39: GFLOPs: 186.4793. Time: 20.2077 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #40: GFLOPs: 188.9283. Time: 19.9458 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #41: GFLOPs: 174.3031. Time: 21.6194 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #42: GFLOPs: 155.2677. Time: 24.2698 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #43: GFLOPs: 123.7886. Time: 30.4416 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #44: GFLOPs: 279.9994. Time: 13.4583 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #45: GFLOPs: 182.1872. Time: 20.6838 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #46: GFLOPs: 112.4506. Time: 33.5109 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #47: GFLOPs: 266.4325. Time: 14.1436 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #48: GFLOPs: 21.9544. Time: 171.6433 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #49: GFLOPs: 167.9874. Time: 22.4322 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #50: GFLOPs: 300.1020. Time: 12.5568 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #51: GFLOPs: 177.1907. Time: 21.2670 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #52: GFLOPs: 207.4983. Time: 18.1607 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #53: GFLOPs: 114.2865. Time: 32.9726 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #54: GFLOPs: 168.4659. Time: 22.3684 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #55: GFLOPs: 46.7633. Time: 80.5828 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #56: GFLOPs: 332.2872. Time: 11.3406 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #57: GFLOPs: 324.8139. Time: 11.6015 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #58: GFLOPs: 108.9527. Time: 34.5868 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #59: GFLOPs: 86.5715. Time: 43.5284 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #60: GFLOPs: 268.3472. Time: 14.0427 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #61: GFLOPs: 76.3700. Time: 49.3429 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #62: GFLOPs: 149.5283. Time: 25.2014 us. Best GFLOPs: 434.6353
2024-03-21 00:11:58 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #63: GFLOPs: 165.0857. Time: 22.8264 us. Best GFLOPs: 434.6353
2024-03-21 00:19:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-03-21 00:19:32 [INFO] [evolutionary_search.cc:715] Picked top 63 candidate(s) from database
2024-03-21 00:19:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 422 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:19:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 841 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:19:36 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2024-03-21 00:19:42 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:19:51 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 103 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:19:59 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 75 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:20:07 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 94 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:20:10 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.8018  1.4854  1.4349  1.4167  1.3862  1.3764  1.3727  1.3369  1.3342  1.3244  1.3216  1.3158  1.3115  1.3115  1.3108  1.3015
[17 : 32]:	1.2948  1.2922  1.2848  1.2832  1.2798  1.2784  1.2704  1.2670  1.2524  1.2468  1.2379  1.2198  1.2132  1.2083  1.2002  1.1995
[33 : 48]:	1.1985  1.1981  1.1905  1.1874  1.1819  1.1808  1.1807  1.1786  1.1730  1.1719  1.1710  1.1636  1.1614  1.1493  1.1483  1.1460
[49 : 64]:	1.1435  1.1427  1.1377  1.1355  1.1324  1.1319  1.1297  1.1274  1.1198  1.1147  1.1101  1.1021  1.1002  1.1002  1.0982  1.0951
2024-03-21 00:20:11 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-03-21 00:20:11 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #64: GFLOPs: 196.2663. Time: 19.2000 us. Best GFLOPs: 434.6353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #65: GFLOPs: 348.8312. Time: 10.8027 us. Best GFLOPs: 434.6353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #66: GFLOPs: 261.1409. Time: 14.4302 us. Best GFLOPs: 434.6353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #67: GFLOPs: 263.5628. Time: 14.2976 us. Best GFLOPs: 434.6353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #68: GFLOPs: 261.0628. Time: 14.4345 us. Best GFLOPs: 434.6353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #69: GFLOPs: 258.7382. Time: 14.5642 us. Best GFLOPs: 434.6353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #70: GFLOPs: 380.3320. Time: 9.9080 us. Best GFLOPs: 434.6353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #71: GFLOPs: 424.0395. Time: 8.8867 us. Best GFLOPs: 434.6353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #72: GFLOPs: 432.5351. Time: 8.7122 us. Best GFLOPs: 434.6353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #73: GFLOPs: 532.3353. Time: 7.0788 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #74: GFLOPs: 513.1624. Time: 7.3433 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #75: GFLOPs: 263.7181. Time: 14.2892 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #76: GFLOPs: 490.0005. Time: 7.6904 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #77: GFLOPs: 487.4886. Time: 7.7301 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #78: GFLOPs: 497.1310. Time: 7.5801 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #79: GFLOPs: 504.0153. Time: 7.4766 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #80: GFLOPs: 501.4951. Time: 7.5142 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #81: GFLOPs: 397.3715. Time: 9.4831 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #82: GFLOPs: 513.1455. Time: 7.3436 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #83: GFLOPs: 401.3071. Time: 9.3901 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #84: GFLOPs: 388.8731. Time: 9.6904 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #85: GFLOPs: 437.6086. Time: 8.6112 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #86: GFLOPs: 335.1185. Time: 11.2447 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #87: GFLOPs: 341.0384. Time: 11.0495 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #88: GFLOPs: 256.5102. Time: 14.6907 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #89: GFLOPs: 397.9764. Time: 9.4687 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #90: GFLOPs: 424.3090. Time: 8.8811 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #91: GFLOPs: 336.9290. Time: 11.1843 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #92: GFLOPs: 310.9079. Time: 12.1204 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #93: GFLOPs: 341.0919. Time: 11.0478 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #94: GFLOPs: 340.2485. Time: 11.0752 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #95: GFLOPs: 172.6448. Time: 21.8270 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #96: GFLOPs: 388.8502. Time: 9.6909 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #97: GFLOPs: 220.2955. Time: 17.1058 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #98: GFLOPs: 334.1482. Time: 11.2774 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #99: GFLOPs: 334.3214. Time: 11.2715 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #100: GFLOPs: 199.5404. Time: 18.8850 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #101: GFLOPs: 341.0348. Time: 11.0497 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #102: GFLOPs: 291.2672. Time: 12.9377 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #103: GFLOPs: 430.8901. Time: 8.7454 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #104: GFLOPs: 291.1815. Time: 12.9415 us. Best GFLOPs: 532.3353
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #105: GFLOPs: 537.7409. Time: 7.0077 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #106: GFLOPs: 356.0722. Time: 10.5830 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #107: GFLOPs: 116.0901. Time: 32.4603 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #108: GFLOPs: 183.4017. Time: 20.5468 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #109: GFLOPs: 155.3277. Time: 24.2604 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #110: GFLOPs: 171.5950. Time: 21.9605 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #111: GFLOPs: 116.5581. Time: 32.3300 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #112: GFLOPs: 388.3738. Time: 9.7028 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #113: GFLOPs: 527.8817. Time: 7.1386 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #114: GFLOPs: 285.1051. Time: 13.2173 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #115: GFLOPs: 341.3760. Time: 11.0386 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #116: GFLOPs: 206.4470. Time: 18.2532 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #117: GFLOPs: 349.2091. Time: 10.7910 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #118: GFLOPs: 228.9628. Time: 16.4582 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #119: GFLOPs: 352.4265. Time: 10.6925 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #120: GFLOPs: 451.8034. Time: 8.3406 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #121: GFLOPs: 172.7002. Time: 21.8200 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #122: GFLOPs: 184.1417. Time: 20.4642 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #123: GFLOPs: 494.7240. Time: 7.6170 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #124: GFLOPs: 171.6542. Time: 21.9530 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #125: GFLOPs: 93.8104. Time: 40.1696 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #126: GFLOPs: 115.1617. Time: 32.7220 us. Best GFLOPs: 537.7409
2024-03-21 00:21:01 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #127: GFLOPs: 185.5595. Time: 20.3079 us. Best GFLOPs: 537.7409
2024-03-21 00:33:14 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-03-21 00:33:16 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-03-21 00:33:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 382 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:33:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 766 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:33:19 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2024-03-21 00:33:26 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 72 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:33:34 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 85 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:33:42 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 88 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:33:51 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 77 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:33:54 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.8651  1.6116  1.5506  1.5252  1.4527  1.4087  1.3906  1.3818  1.3591  1.3532  1.3521  1.3481  1.3467  1.3441  1.3375  1.3252
[17 : 32]:	1.3147  1.3088  1.3039  1.3033  1.3011  1.2972  1.2949  1.2914  1.2898  1.2839  1.2650  1.2457  1.2435  1.2395  1.2390  1.2267
[33 : 48]:	1.2234  1.2224  1.2217  1.2176  1.2127  1.2009  1.1992  1.1885  1.1723  1.1624  1.1366  1.1229  1.1122  1.1093  1.1082  1.1082
[49 : 64]:	1.1077  1.1073  1.1047  1.1027  1.0946  1.0941  1.0893  1.0886  1.0861  1.0860  1.0851  1.0811  1.0787  1.0770  1.0767  1.0757
2024-03-21 00:33:54 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-03-21 00:33:54 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #128: GFLOPs: 448.4969. Time: 8.4021 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #129: GFLOPs: 139.4887. Time: 27.0152 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #130: GFLOPs: 370.2872. Time: 10.1767 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #131: GFLOPs: 174.3079. Time: 21.6188 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #132: GFLOPs: 450.0422. Time: 8.3733 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #133: GFLOPs: 140.4501. Time: 26.8303 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #134: GFLOPs: 505.4802. Time: 7.4549 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #135: GFLOPs: 505.5987. Time: 7.4532 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #136: GFLOPs: 409.0970. Time: 9.2113 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #137: GFLOPs: 405.3924. Time: 9.2955 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #138: GFLOPs: 317.1601. Time: 11.8814 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #139: GFLOPs: 411.0815. Time: 9.1668 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #140: GFLOPs: 405.4101. Time: 9.2951 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #141: GFLOPs: 415.2178. Time: 9.0755 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #142: GFLOPs: 192.8197. Time: 19.5432 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #143: GFLOPs: 173.0381. Time: 21.7774 us. Best GFLOPs: 537.7409
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #144: GFLOPs: 551.1558. Time: 6.8371 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #145: GFLOPs: 200.3057. Time: 18.8128 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #146: GFLOPs: 434.4326. Time: 8.6741 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #147: GFLOPs: 407.2906. Time: 9.2522 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #148: GFLOPs: 173.0718. Time: 21.7732 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #149: GFLOPs: 344.4768. Time: 10.9393 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #150: GFLOPs: 403.5703. Time: 9.3375 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #151: GFLOPs: 441.7577. Time: 8.5303 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #152: GFLOPs: 200.2989. Time: 18.8135 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #153: GFLOPs: 344.4744. Time: 10.9393 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #154: GFLOPs: 202.4670. Time: 18.6120 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #155: GFLOPs: 386.8213. Time: 9.7418 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #156: GFLOPs: 522.8626. Time: 7.2071 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #157: GFLOPs: 386.8092. Time: 9.7421 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #158: GFLOPs: 276.5956. Time: 13.6239 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #159: GFLOPs: 282.5647. Time: 13.3361 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #160: GFLOPs: 199.1656. Time: 18.9205 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #161: GFLOPs: 401.8821. Time: 9.3767 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #162: GFLOPs: 293.6243. Time: 12.8338 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #163: GFLOPs: 271.5747. Time: 13.8758 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #164: GFLOPs: 513.6882. Time: 7.3358 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #165: GFLOPs: 448.4165. Time: 8.4036 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #166: GFLOPs: 276.8969. Time: 13.6091 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #167: GFLOPs: 272.5795. Time: 13.8247 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #168: GFLOPs: 513.5939. Time: 7.3372 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #169: GFLOPs: 434.3788. Time: 8.6752 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #170: GFLOPs: 108.5159. Time: 34.7260 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #171: GFLOPs: 239.7656. Time: 15.7167 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #172: GFLOPs: 504.6628. Time: 7.4670 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #173: GFLOPs: 518.0736. Time: 7.2737 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #174: GFLOPs: 513.2756. Time: 7.3417 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #175: GFLOPs: 513.2913. Time: 7.3415 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #176: GFLOPs: 434.3733. Time: 8.6753 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #177: GFLOPs: 334.8527. Time: 11.2537 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #178: GFLOPs: 504.6058. Time: 7.4678 us. Best GFLOPs: 551.1558
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #179: GFLOPs: 553.8635. Time: 6.8037 us. Best GFLOPs: 553.8635
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #180: GFLOPs: 419.2304. Time: 8.9887 us. Best GFLOPs: 553.8635
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #181: GFLOPs: 441.4304. Time: 8.5366 us. Best GFLOPs: 553.8635
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #182: GFLOPs: 136.7489. Time: 27.5565 us. Best GFLOPs: 553.8635
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #183: GFLOPs: 434.6649. Time: 8.6695 us. Best GFLOPs: 553.8635
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #184: GFLOPs: 327.4405. Time: 11.5084 us. Best GFLOPs: 553.8635
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #185: GFLOPs: 329.3971. Time: 11.4401 us. Best GFLOPs: 553.8635
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #186: GFLOPs: 288.2554. Time: 13.0729 us. Best GFLOPs: 553.8635
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #187: GFLOPs: 543.4223. Time: 6.9344 us. Best GFLOPs: 553.8635
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #188: GFLOPs: 381.6462. Time: 9.8739 us. Best GFLOPs: 553.8635
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #189: GFLOPs: 81.8076. Time: 46.0632 us. Best GFLOPs: 553.8635
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #190: GFLOPs: 279.6912. Time: 13.4731 us. Best GFLOPs: 553.8635
2024-03-21 00:34:41 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #191: GFLOPs: 171.4677. Time: 21.9769 us. Best GFLOPs: 553.8635
2024-03-21 00:51:37 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-03-21 00:51:39 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-03-21 00:51:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 385 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:51:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 768 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:51:42 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2024-03-21 00:51:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 80 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:51:57 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 77 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:52:05 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 85 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:52:14 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 85 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 00:52:17 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.7408  1.7290  1.6749  1.6666  1.6486  1.6485  1.6274  1.6185  1.6162  1.6162  1.5952  1.5930  1.5874  1.5856  1.5473  1.5450
[17 : 32]:	1.5240  1.5123  1.3942  1.3942  1.3379  1.3249  1.3095  1.2948  1.2639  1.2344  1.1979  1.1860  1.1484  1.1435  1.1399  1.1338
[33 : 48]:	1.1334  1.1027  1.0938  1.0919  1.0877  1.0645  1.0620  1.0509  1.0479  1.0450  1.0386  1.0382  1.0197  1.0179  1.0170  1.0133
[49 : 64]:	1.0041  1.0036  1.0030  1.0012  1.0010  0.9953  0.9903  0.9841  0.9820  0.9802  0.9795  0.9786  0.9783  0.9781  0.9757  0.9752
2024-03-21 00:52:17 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-03-21 00:52:17 [INFO] [evolutionary_search.cc:730] Sending 63 candidates(s) for measurement
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #192: GFLOPs: 88.5437. Time: 42.5589 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #193: GFLOPs: 85.2525. Time: 44.2019 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #194: GFLOPs: 85.2500. Time: 44.2032 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #195: GFLOPs: 71.4378. Time: 52.7496 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #196: GFLOPs: 118.0845. Time: 31.9121 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #197: GFLOPs: 87.1061. Time: 43.2613 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #198: GFLOPs: 71.6081. Time: 52.6242 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #199: GFLOPs: 101.4361. Time: 37.1497 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #200: GFLOPs: 109.3749. Time: 34.4532 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #201: GFLOPs: 109.3796. Time: 34.4518 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #202: GFLOPs: 105.2886. Time: 35.7904 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #203: GFLOPs: 115.1791. Time: 32.7170 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #204: GFLOPs: 106.9531. Time: 35.2334 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #205: GFLOPs: 86.8785. Time: 43.3746 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #206: GFLOPs: 103.9922. Time: 36.2366 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #207: GFLOPs: 111.5438. Time: 33.7833 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #208: GFLOPs: 109.6797. Time: 34.3575 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #209: GFLOPs: 119.5723. Time: 31.5150 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #210: GFLOPs: 303.0846. Time: 12.4332 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #211: GFLOPs: 294.1090. Time: 12.8127 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #212: GFLOPs: 123.2565. Time: 30.5730 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #213: GFLOPs: 207.3818. Time: 18.1709 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #214: GFLOPs: 503.7913. Time: 7.4799 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #215: GFLOPs: 486.7673. Time: 7.7415 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #216: GFLOPs: 462.2234. Time: 8.1526 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #217: GFLOPs: 441.2750. Time: 8.5396 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #218: GFLOPs: 122.7357. Time: 30.7027 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #219: GFLOPs: 427.9569. Time: 8.8054 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #220: GFLOPs: 386.6317. Time: 9.7465 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #221: GFLOPs: 386.4622. Time: 9.7508 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #222: GFLOPs: 413.0133. Time: 9.1240 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #223: GFLOPs: 96.9907. Time: 38.8524 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #224: GFLOPs: 392.2311. Time: 9.6074 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #225: GFLOPs: 478.4192. Time: 7.8766 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #226: GFLOPs: 392.2239. Time: 9.6076 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #227: GFLOPs: 270.9199. Time: 13.9093 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #228: GFLOPs: 95.4490. Time: 39.4799 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #229: GFLOPs: 356.2487. Time: 10.5778 us. Best GFLOPs: 553.8635
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #230: GFLOPs: 574.7829. Time: 6.5561 us. Best GFLOPs: 574.7829
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #231: GFLOPs: 172.0657. Time: 21.9005 us. Best GFLOPs: 574.7829
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #232: GFLOPs: 171.0283. Time: 22.0333 us. Best GFLOPs: 574.7829
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #233: GFLOPs: 412.7345. Time: 9.1301 us. Best GFLOPs: 574.7829
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #234: GFLOPs: 421.5559. Time: 8.9391 us. Best GFLOPs: 574.7829
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #235: GFLOPs: 509.1733. Time: 7.4009 us. Best GFLOPs: 574.7829
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #236: GFLOPs: 388.9160. Time: 9.6893 us. Best GFLOPs: 574.7829
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #237: GFLOPs: 411.7829. Time: 9.1512 us. Best GFLOPs: 574.7829
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #238: GFLOPs: 569.9224. Time: 6.6120 us. Best GFLOPs: 574.7829
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #239: GFLOPs: 421.2053. Time: 8.9465 us. Best GFLOPs: 574.7829
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #240: GFLOPs: 576.4484. Time: 6.5371 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #241: GFLOPs: 549.0696. Time: 6.8631 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #242: GFLOPs: 509.2437. Time: 7.3998 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #243: GFLOPs: 518.0182. Time: 7.2745 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #244: GFLOPs: 505.9461. Time: 7.4481 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #245: GFLOPs: 417.5146. Time: 9.0256 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #246: GFLOPs: 378.4435. Time: 9.9574 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #247: GFLOPs: 538.7011. Time: 6.9952 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #248: GFLOPs: 572.3344. Time: 6.5841 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #249: GFLOPs: 415.5983. Time: 9.0672 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #250: GFLOPs: 382.5853. Time: 9.8496 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #251: GFLOPs: 570.7708. Time: 6.6022 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #252: GFLOPs: 491.2786. Time: 7.6704 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #253: GFLOPs: 307.4406. Time: 12.2571 us. Best GFLOPs: 576.4484
2024-03-21 00:53:07 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #254: GFLOPs: 187.5820. Time: 20.0889 us. Best GFLOPs: 576.4484
2024-03-21 01:06:21 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-03-21 01:06:23 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-03-21 01:06:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 393 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:06:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 783 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:06:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 1177 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:06:28 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2024-03-21 01:06:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 91 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:06:42 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 71 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:06:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 88 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:06:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 70 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:07:02 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.7196  1.7191  1.6934  1.6272  1.5152  1.5142  1.4399  1.4000  1.3696  1.3669  1.3499  1.3480  1.3401  1.3113  1.3038  1.2919
[17 : 32]:	1.2910  1.2867  1.2755  1.2737  1.2622  1.2261  1.2095  1.2009  1.1815  1.1490  1.1363  1.1216  1.0903  1.0866  1.0835  1.0787
[33 : 48]:	1.0784  1.0715  1.0601  1.0534  1.0407  1.0399  1.0345  1.0280  1.0265  1.0180  1.0159  1.0131  1.0121  1.0106  1.0106  1.0095
[49 : 64]:	1.0033  1.0029  1.0027  1.0014  1.0013  1.0007  0.9971  0.9964  0.9959  0.9942  0.9874  0.9844  0.9841  0.9821  0.9819  0.9798
2024-03-21 01:07:02 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-03-21 01:07:03 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #255: GFLOPs: 380.4028. Time: 9.9061 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #256: GFLOPs: 425.4244. Time: 8.8578 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #257: GFLOPs: 407.7507. Time: 9.2417 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #258: GFLOPs: 462.0092. Time: 8.1564 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #259: GFLOPs: 293.2725. Time: 12.8492 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #260: GFLOPs: 304.9829. Time: 12.3558 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #261: GFLOPs: 324.6495. Time: 11.6073 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #262: GFLOPs: 331.6235. Time: 11.3632 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #263: GFLOPs: 476.3183. Time: 7.9113 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #264: GFLOPs: 484.2867. Time: 7.7812 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #265: GFLOPs: 391.4461. Time: 9.6267 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #266: GFLOPs: 449.5650. Time: 8.3821 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #267: GFLOPs: 522.2203. Time: 7.2160 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #268: GFLOPs: 512.6873. Time: 7.3501 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #269: GFLOPs: 522.6757. Time: 7.2097 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #270: GFLOPs: 542.6887. Time: 6.9438 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #271: GFLOPs: 511.6207. Time: 7.3655 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #272: GFLOPs: 511.6164. Time: 7.3655 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #273: GFLOPs: 526.4733. Time: 7.1577 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #274: GFLOPs: 522.2370. Time: 7.2157 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #275: GFLOPs: 522.2607. Time: 7.2154 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #276: GFLOPs: 426.5721. Time: 8.8340 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #277: GFLOPs: 109.4113. Time: 34.4418 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #278: GFLOPs: 251.8061. Time: 14.9652 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #279: GFLOPs: 454.8221. Time: 8.2853 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #280: GFLOPs: 316.8989. Time: 11.8912 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #281: GFLOPs: 575.7268. Time: 6.5453 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #282: GFLOPs: 316.8508. Time: 11.8930 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #283: GFLOPs: 66.5909. Time: 56.5891 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #284: GFLOPs: 543.0947. Time: 6.9386 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #285: GFLOPs: 335.9040. Time: 11.2184 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #286: GFLOPs: 78.5079. Time: 47.9993 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #287: GFLOPs: 564.3015. Time: 6.6778 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #288: GFLOPs: 564.2934. Time: 6.6779 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #289: GFLOPs: 407.2773. Time: 9.2525 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #290: GFLOPs: 426.0939. Time: 8.8439 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #291: GFLOPs: 67.0379. Time: 56.2118 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #292: GFLOPs: 575.7954. Time: 6.5445 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #293: GFLOPs: 170.1688. Time: 22.1446 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #294: GFLOPs: 172.3304. Time: 21.8668 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #295: GFLOPs: 573.1505. Time: 6.5747 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #296: GFLOPs: 504.5188. Time: 7.4691 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #297: GFLOPs: 412.0877. Time: 9.1445 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #298: GFLOPs: 348.6430. Time: 10.8085 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #299: GFLOPs: 562.8933. Time: 6.6946 us. Best GFLOPs: 576.4484
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #300: GFLOPs: 576.7682. Time: 6.5335 us. Best GFLOPs: 576.7682
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #301: GFLOPs: 577.6408. Time: 6.5236 us. Best GFLOPs: 577.6408
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #302: GFLOPs: 577.3015. Time: 6.5275 us. Best GFLOPs: 577.6408
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #303: GFLOPs: 577.8704. Time: 6.5210 us. Best GFLOPs: 577.8704
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #304: GFLOPs: 578.2104. Time: 6.5172 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #305: GFLOPs: 578.1220. Time: 6.5182 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #306: GFLOPs: 169.0308. Time: 22.2937 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #307: GFLOPs: 576.7432. Time: 6.5338 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #308: GFLOPs: 577.9479. Time: 6.5202 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #309: GFLOPs: 173.2288. Time: 21.7534 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #310: GFLOPs: 577.3731. Time: 6.5267 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #311: GFLOPs: 349.3044. Time: 10.7881 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #312: GFLOPs: 577.2891. Time: 6.5276 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #313: GFLOPs: 570.6641. Time: 6.6034 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #314: GFLOPs: 577.5549. Time: 6.5246 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #315: GFLOPs: 500.4023. Time: 7.5306 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #316: GFLOPs: 165.1743. Time: 22.8142 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #317: GFLOPs: 235.1404. Time: 16.0258 us. Best GFLOPs: 578.2104
2024-03-21 01:07:49 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #318: GFLOPs: 190.4036. Time: 19.7912 us. Best GFLOPs: 578.2104
2024-03-21 01:31:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-03-21 01:31:13 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-03-21 01:31:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 386 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:31:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 773 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:31:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 1160 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:31:18 [INFO] [evolutionary_search.cc:723] Sampled 70 candidate(s)
2024-03-21 01:31:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 67 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:31:32 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 91 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:31:41 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 89 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:31:49 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 83 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:31:52 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.3967  1.3348  1.3344  1.2976  1.2745  1.2678  1.2554  1.2496  1.2489  1.2480  1.2025  1.1986  1.1879  1.1677  1.1572  1.1468
[17 : 32]:	1.1397  1.1378  1.1363  1.0789  1.0771  1.0668  1.0663  1.0643  1.0603  1.0482  1.0438  1.0435  1.0391  1.0327  1.0267  1.0252
[33 : 48]:	1.0252  1.0183  1.0163  1.0155  1.0153  1.0147  1.0140  1.0124  1.0119  1.0116  1.0113  1.0111  1.0092  1.0083  1.0079  1.0068
[49 : 64]:	1.0066  1.0057  1.0027  1.0027  1.0023  1.0021  1.0003  1.0000  1.0000  1.0000  0.9993  0.9980  0.9974  0.9973  0.9971  0.9959
2024-03-21 01:31:52 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-03-21 01:31:52 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #319: GFLOPs: 361.4532. Time: 10.4255 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #320: GFLOPs: 386.8983. Time: 9.7398 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #321: GFLOPs: 409.6991. Time: 9.1978 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #322: GFLOPs: 409.3613. Time: 9.2054 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #323: GFLOPs: 338.3331. Time: 11.1379 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #324: GFLOPs: 325.2608. Time: 11.5855 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #325: GFLOPs: 356.2398. Time: 10.5780 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #326: GFLOPs: 172.8007. Time: 21.8073 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #327: GFLOPs: 299.7264. Time: 12.5725 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #328: GFLOPs: 340.1489. Time: 11.0784 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #329: GFLOPs: 351.9766. Time: 10.7062 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #330: GFLOPs: 361.7010. Time: 10.4183 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #331: GFLOPs: 264.1125. Time: 14.2679 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #332: GFLOPs: 411.9296. Time: 9.1480 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #333: GFLOPs: 331.3397. Time: 11.3730 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #334: GFLOPs: 474.6957. Time: 7.9384 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #335: GFLOPs: 443.2813. Time: 8.5010 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #336: GFLOPs: 430.5713. Time: 8.7519 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #337: GFLOPs: 462.0661. Time: 8.1554 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #338: GFLOPs: 316.8645. Time: 11.8925 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #339: GFLOPs: 462.1441. Time: 8.1540 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #340: GFLOPs: 180.9804. Time: 20.8217 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #341: GFLOPs: 294.7309. Time: 12.7856 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #342: GFLOPs: 310.1935. Time: 12.1483 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #343: GFLOPs: 294.6683. Time: 12.7883 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #344: GFLOPs: 308.7203. Time: 12.2063 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #345: GFLOPs: 574.3517. Time: 6.5610 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #346: GFLOPs: 575.6152. Time: 6.5466 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #347: GFLOPs: 143.2473. Time: 26.3064 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #348: GFLOPs: 435.9660. Time: 8.6436 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #349: GFLOPs: 304.1197. Time: 12.3909 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #350: GFLOPs: 297.8082. Time: 12.6535 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #351: GFLOPs: 304.3447. Time: 12.3818 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #352: GFLOPs: 363.2943. Time: 10.3726 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #353: GFLOPs: 574.4130. Time: 6.5603 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #354: GFLOPs: 576.5100. Time: 6.5364 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #355: GFLOPs: 575.6774. Time: 6.5459 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #356: GFLOPs: 180.9099. Time: 20.8298 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #357: GFLOPs: 574.7007. Time: 6.5570 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #358: GFLOPs: 574.2898. Time: 6.5617 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #359: GFLOPs: 552.3734. Time: 6.8221 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #360: GFLOPs: 577.1823. Time: 6.5288 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #361: GFLOPs: 575.5967. Time: 6.5468 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #362: GFLOPs: 575.4780. Time: 6.5482 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #363: GFLOPs: 575.5444. Time: 6.5474 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #364: GFLOPs: 575.3072. Time: 6.5501 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #365: GFLOPs: 576.2097. Time: 6.5398 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #366: GFLOPs: 575.2356. Time: 6.5509 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #367: GFLOPs: 574.9801. Time: 6.5538 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #368: GFLOPs: 229.4912. Time: 16.4203 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #369: GFLOPs: 576.4654. Time: 6.5369 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #370: GFLOPs: 574.6250. Time: 6.5579 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #371: GFLOPs: 574.1793. Time: 6.5630 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #372: GFLOPs: 575.1094. Time: 6.5524 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #373: GFLOPs: 574.9138. Time: 6.5546 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #374: GFLOPs: 574.0719. Time: 6.5642 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #375: GFLOPs: 575.1323. Time: 6.5521 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #376: GFLOPs: 573.3881. Time: 6.5720 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #377: GFLOPs: 239.1943. Time: 15.7542 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #378: GFLOPs: 574.9659. Time: 6.5540 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #379: GFLOPs: 569.6509. Time: 6.6151 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #380: GFLOPs: 23.8493. Time: 158.0054 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #381: GFLOPs: 236.8952. Time: 15.9071 us. Best GFLOPs: 578.2104
2024-03-21 01:32:39 [INFO] [task_scheduler.cc:131] [Task #32: fused_nn_contrib_conv2d_winograd_without_weight_transform] Trial #382: GFLOPs: 241.4270. Time: 15.6085 us. Best GFLOPs: 578.2104
2024-03-21 01:55:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-03-21 01:55:43 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-03-21 01:55:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 392 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:55:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 786 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:55:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 1170 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:55:48 [INFO] [evolutionary_search.cc:723] Sampled 60 candidate(s)
2024-03-21 01:55:54 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 68 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:56:02 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 73 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
2024-03-21 01:56:11 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5729a5cba108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x5729a5d04b28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x5729a4ba4818)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x5729a6ac5718)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x5729a4d2ad68)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x5729a48e7228)]: 79 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x57299e9f8b38)]: 0 failure(s)
