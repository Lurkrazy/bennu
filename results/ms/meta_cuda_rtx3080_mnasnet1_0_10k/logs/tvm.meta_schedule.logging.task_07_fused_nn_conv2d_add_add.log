2024-03-21 19:46:24 [INFO] [task_scheduler.cc:160] Initializing Task #7: "fused_nn_conv2d_add_add"
2024-03-21 19:46:24 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(72), T.int64(56), T.int64(56)), "float32"), p1: T.Buffer((T.int64(24), T.int64(72), T.int64(1), T.int64(1)), "float32"), p2: T.Buffer((T.int64(1), T.int64(24), T.int64(1), T.int64(1)), "float32"), p3: T.Buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(72), T.int64(56), T.int64(56)))
        conv2d_nchw = T.alloc_buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)))
        T_add_1 = T.alloc_buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(72), T.int64(56), T.int64(56)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(p0[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = p0[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(24), T.int64(56), T.int64(56), T.int64(72), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], p1[v_ff, v_rc, v_ry, v_rx])
                T.writes(conv2d_nchw[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    conv2d_nchw[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                conv2d_nchw[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * p1[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(24), T.int64(56), T.int64(56)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(conv2d_nchw[v_ax0, v_ax1, v_ax2, v_ax3], p2[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add_1[v_ax0, v_ax1, v_ax2, v_ax3] = conv2d_nchw[v_ax0, v_ax1, v_ax2, v_ax3] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(24), T.int64(56), T.int64(56)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3], p3[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3] = T_add_1[v_ax0, v_ax1, v_ax2, v_ax3] + p3[v_ax0, v_ax1, v_ax2, v_ax3]
2024-03-21 19:46:24 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-03-21 19:46:24 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(72), T.int64(56), T.int64(56)), "float32"), p1: T.Buffer((T.int64(24), T.int64(72), T.int64(1), T.int64(1)), "float32"), p2: T.Buffer((T.int64(1), T.int64(24), T.int64(1), T.int64(1)), "float32"), p3: T.Buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 1024})
            conv2d_nchw_local = T.alloc_buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)), scope="local")
            pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(72), T.int64(56), T.int64(56)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(24), T.int64(72), T.int64(1), T.int64(1)), scope="shared")
            for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x"):
                for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(7), thread="vthread.x"):
                    for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                        for rc_0, ry_0, rx_0 in T.grid(T.int64(6), T.int64(1), T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(4704)):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(72), rc_0 * T.int64(12) + ax0_ax1_ax2_ax3_fused // T.int64(392))
                                    v2 = T.axis.spatial(T.int64(56), ax0_ax1_ax2_ax3_fused % T.int64(392) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(56), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(7) + ax0_ax1_ax2_ax3_fused % T.int64(7))
                                    T.reads(p0[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    pad_temp_shared[v0, v1, v2, v3] = p0[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(144)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(24), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(12) + ax0_ax1_ax2_ax3_fused // T.int64(12))
                                    v1 = T.axis.spatial(T.int64(72), rc_0 * T.int64(12) + ax0_ax1_ax2_ax3_fused % T.int64(12))
                                    v2 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v3 = T.axis.spatial(T.int64(1), T.int64(0))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(6), T.int64(28), T.int64(1), T.int64(12), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                                with T.block("conv2d_nchw"):
                                    v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                    v_ff = T.axis.spatial(T.int64(24), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(12) + ff_3 * T.int64(2) + ff_4)
                                    v_yy = T.axis.spatial(T.int64(56), yy_3 * T.int64(2) + yy_4)
                                    v_xx = T.axis.spatial(T.int64(56), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(7) + nn_1_ff_1_yy_1_xx_1_fused + xx_3 + xx_4)
                                    v_rc = T.axis.reduce(T.int64(72), rc_0 * T.int64(12) + rc_1 * T.int64(12) + rc_2)
                                    v_ry = T.axis.reduce(T.int64(1), ry_0 + ry_1 + ry_2)
                                    v_rx = T.axis.reduce(T.int64(1), rx_0 + rx_1 + rx_2)
                                    T.reads(pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], p1_shared[v_ff, v_rc, v_ry, v_rx])
                                    T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                                    conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * p1_shared[v_ff, v_rc, v_ry, v_rx]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(56), T.int64(1)):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(T.int64(1), ax0)
                                v1 = T.axis.spatial(T.int64(24), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(12) + ax1)
                                v2 = T.axis.spatial(T.int64(56), ax2)
                                v3 = T.axis.spatial(T.int64(56), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(7) + nn_1_ff_1_yy_1_xx_1_fused + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], p2[v0, v1, T.int64(0), T.int64(0)], p3[v0, v1, v2, v3])
                                T.writes(T_add[v0, v1, v2, v3])
                                T_add[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3] + p2[v0, v1, T.int64(0), T.int64(0)] + p3[v0, v1, v2, v3]
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 1, 1, 6, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 1, 28, 2])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[8, 7, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[6, 1, 12])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v100 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v100)
2024-03-21 19:46:24 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(72), T.int64(56), T.int64(56)), "float32"), p1: T.Buffer((T.int64(24), T.int64(72), T.int64(1), T.int64(1)), "float32"), p2: T.Buffer((T.int64(1), T.int64(24), T.int64(1), T.int64(1)), "float32"), p3: T.Buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 0})
            conv2d_nchw_local = T.alloc_buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)), scope="local")
            pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(72), T.int64(56), T.int64(56)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(24), T.int64(72), T.int64(1), T.int64(1)), scope="shared")
            for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x"):
                for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(7), thread="vthread.x"):
                    for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                        for rc_0_ry_0_rx_0_fused in T.serial(T.int64(6), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(4704)):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(72), rc_0_ry_0_rx_0_fused * T.int64(12) + ax0_ax1_ax2_ax3_fused // T.int64(392))
                                    v2 = T.axis.spatial(T.int64(56), ax0_ax1_ax2_ax3_fused % T.int64(392) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(56), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(7) + ax0_ax1_ax2_ax3_fused % T.int64(7))
                                    T.reads(p0[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    pad_temp_shared[v0, v1, v2, v3] = p0[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(144)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(24), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(12) + ax0_ax1_ax2_ax3_fused // T.int64(12))
                                    v1 = T.axis.spatial(T.int64(72), rc_0_ry_0_rx_0_fused * T.int64(12) + ax0_ax1_ax2_ax3_fused % T.int64(12))
                                    v2 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v3 = T.axis.spatial(T.int64(1), T.int64(0))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(6), T.int64(28), T.int64(1), T.int64(12), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                                with T.block("conv2d_nchw"):
                                    v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                    v_ff = T.axis.spatial(T.int64(24), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(12) + ff_3 * T.int64(2) + ff_4)
                                    v_yy = T.axis.spatial(T.int64(56), yy_3 * T.int64(2) + yy_4)
                                    v_xx = T.axis.spatial(T.int64(56), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(7) + nn_1_ff_1_yy_1_xx_1_fused + xx_3 + xx_4)
                                    v_rc = T.axis.reduce(T.int64(72), rc_0_ry_0_rx_0_fused * T.int64(12) + rc_1 * T.int64(12) + rc_2)
                                    v_ry = T.axis.reduce(T.int64(1), ry_1 + ry_2)
                                    v_rx = T.axis.reduce(T.int64(1), rx_1 + rx_2)
                                    T.reads(pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], p1_shared[v_ff, v_rc, v_ry, v_rx])
                                    T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                                    conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * p1_shared[v_ff, v_rc, v_ry, v_rx]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(56), T.int64(1)):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(T.int64(1), ax0)
                                v1 = T.axis.spatial(T.int64(24), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(12) + ax1)
                                v2 = T.axis.spatial(T.int64(56), ax2)
                                v3 = T.axis.spatial(T.int64(56), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(7) + nn_1_ff_1_yy_1_xx_1_fused + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], p2[v0, v1, T.int64(0), T.int64(0)], p3[v0, v1, v2, v3])
                                T.writes(T_add[v0, v1, v2, v3])
                                T_add[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3] + p2[v0, v1, T.int64(0), T.int64(0)] + p3[v0, v1, v2, v3]
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 1, 1, 6, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 1, 28, 2])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[8, 7, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[6, 1, 12])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
l100 = sch.fuse(l55, l61, l67, preserve_unit_iters=True)
sch.annotate(block_or_loop=l100, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l100, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l100, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v101 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v101)
2024-03-21 19:46:24 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(72), T.int64(56), T.int64(56)), "float32"), p1: T.Buffer((T.int64(24), T.int64(72), T.int64(1), T.int64(1)), "float32"), p2: T.Buffer((T.int64(1), T.int64(24), T.int64(1), T.int64(1)), "float32"), p3: T.Buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 64})
            conv2d_nchw_local = T.alloc_buffer((T.int64(1), T.int64(24), T.int64(56), T.int64(56)), scope="local")
            pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(72), T.int64(56), T.int64(56)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(24), T.int64(72), T.int64(1), T.int64(1)), scope="shared")
            for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x"):
                for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(7), thread="vthread.x"):
                    for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                        for rc_0_ry_0_rx_0_fused in T.serial(T.int64(6), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(4704)):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(72), rc_0_ry_0_rx_0_fused * T.int64(12) + ax0_ax1_ax2_ax3_fused // T.int64(392))
                                    v2 = T.axis.spatial(T.int64(56), ax0_ax1_ax2_ax3_fused % T.int64(392) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(56), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(7) + ax0_ax1_ax2_ax3_fused % T.int64(7))
                                    T.reads(p0[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    pad_temp_shared[v0, v1, v2, v3] = p0[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(144)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(24), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(12) + ax0_ax1_ax2_ax3_fused // T.int64(12))
                                    v1 = T.axis.spatial(T.int64(72), rc_0_ry_0_rx_0_fused * T.int64(12) + ax0_ax1_ax2_ax3_fused % T.int64(12))
                                    v2 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v3 = T.axis.spatial(T.int64(1), T.int64(0))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(6), T.int64(28), T.int64(1), T.int64(12), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                                with T.block("conv2d_nchw"):
                                    v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                    v_ff = T.axis.spatial(T.int64(24), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(12) + ff_3 * T.int64(2) + ff_4)
                                    v_yy = T.axis.spatial(T.int64(56), yy_3 * T.int64(2) + yy_4)
                                    v_xx = T.axis.spatial(T.int64(56), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(7) + nn_1_ff_1_yy_1_xx_1_fused + xx_3 + xx_4)
                                    v_rc = T.axis.reduce(T.int64(72), rc_0_ry_0_rx_0_fused * T.int64(12) + rc_1 * T.int64(12) + rc_2)
                                    v_ry = T.axis.reduce(T.int64(1), ry_1 + ry_2)
                                    v_rx = T.axis.reduce(T.int64(1), rx_1 + rx_2)
                                    T.reads(pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], p1_shared[v_ff, v_rc, v_ry, v_rx])
                                    T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                                    conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * p1_shared[v_ff, v_rc, v_ry, v_rx]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(56), T.int64(1)):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(T.int64(1), ax0)
                                v1 = T.axis.spatial(T.int64(24), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(12) + ax1)
                                v2 = T.axis.spatial(T.int64(56), ax2)
                                v3 = T.axis.spatial(T.int64(56), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) * T.int64(7) + nn_1_ff_1_yy_1_xx_1_fused + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], p2[v0, v1, T.int64(0), T.int64(0)], p3[v0, v1, v2, v3])
                                T.writes(T_add[v0, v1, v2, v3])
                                T_add[v0, v1, v2, v3] = conv2d_nchw_local[v0, v1, v2, v3] + p2[v0, v1, T.int64(0), T.int64(0)] + p3[v0, v1, v2, v3]
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l17, l18, l19, l20, l21 = sch.split(loop=l5, factors=[v12, v13, v14, v15, v16], preserve_unit_iters=True)
v22, v23, v24, v25, v26 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[2, 1, 1, 6, 2])
l27, l28, l29, l30, l31 = sch.split(loop=l6, factors=[v22, v23, v24, v25, v26], preserve_unit_iters=True)
v32, v33, v34, v35, v36 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 1, 1, 28, 2])
l37, l38, l39, l40, l41 = sch.split(loop=l7, factors=[v32, v33, v34, v35, v36], preserve_unit_iters=True)
v42, v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[8, 7, 1, 1, 1])
l47, l48, l49, l50, l51 = sch.split(loop=l8, factors=[v42, v43, v44, v45, v46], preserve_unit_iters=True)
v52, v53, v54 = sch.sample_perfect_tile(loop=l9, n=3, max_innermost_factor=64, decision=[6, 1, 12])
l55, l56, l57 = sch.split(loop=l9, factors=[v52, v53, v54], preserve_unit_iters=True)
v58, v59, v60 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l61, l62, l63 = sch.split(loop=l10, factors=[v58, v59, v60], preserve_unit_iters=True)
v64, v65, v66 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l67, l68, l69 = sch.split(loop=l11, factors=[v64, v65, v66], preserve_unit_iters=True)
sch.reorder(l17, l27, l37, l47, l18, l28, l38, l48, l19, l29, l39, l49, l55, l61, l67, l56, l62, l68, l20, l30, l40, l50, l57, l63, l69, l21, l31, l41, l51)
l70 = sch.fuse(l17, l27, l37, l47, preserve_unit_iters=True)
sch.bind(loop=l70, thread_axis="blockIdx.x")
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="vthread.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b73 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b73, loop=l72, preserve_unit_loops=True, index=-1)
b74 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b74, loop=l67, preserve_unit_loops=True, index=-1)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b74)
l85 = sch.fuse(l81, l82, l83, l84, preserve_unit_iters=True)
v86 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b74, ann_key="meta_schedule.cooperative_fetch", ann_val=v86)
b87 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b87, loop=l67, preserve_unit_loops=True, index=-1)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97 = sch.get_loops(block=b87)
l98 = sch.fuse(l94, l95, l96, l97, preserve_unit_iters=True)
v99 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b87, ann_key="meta_schedule.cooperative_fetch", ann_val=v99)
l100 = sch.fuse(l55, l61, l67, preserve_unit_iters=True)
sch.annotate(block_or_loop=l100, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l100, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l100, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v101 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v101)
2024-03-21 19:54:01 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-03-21 19:54:01 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-03-21 19:54:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 492 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 19:54:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 974 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 19:54:02 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2024-03-21 19:54:03 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 101 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 19:54:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 95 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 19:54:06 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 93 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 19:54:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 81 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 19:54:08 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9985  0.9972  0.9972  0.9969  0.9968  0.9966  0.9964  0.9953  0.9937  0.9937  0.9932  0.9917  0.9917  0.9900  0.9888  0.9854
[17 : 32]:	0.9852  0.9850  0.9823  0.9819  0.9817  0.9817  0.9811  0.9804  0.9803  0.9799  0.9786  0.9784  0.9781  0.9780  0.9753  0.9752
[33 : 48]:	0.9743  0.9740  0.9738  0.9729  0.9704  0.9698  0.9675  0.9670  0.9662  0.9654  0.9650  0.9642  0.9635  0.9630  0.9621  0.9615
[49 : 64]:	0.9607  0.9605  0.9604  0.9603  0.9598  0.9580  0.9565  0.9563  0.9560  0.9558  0.9553  0.9553  0.9550  0.9541  0.9541  0.9523
2024-03-21 19:54:08 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-03-21 19:54:08 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #1: GFLOPs: 647.6686. Time: 16.9663 us. Best GFLOPs: 647.6686
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #2: GFLOPs: 522.2398. Time: 21.0412 us. Best GFLOPs: 647.6686
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #3: GFLOPs: 631.5866. Time: 17.3983 us. Best GFLOPs: 647.6686
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #4: GFLOPs: 285.6893. Time: 38.4633 us. Best GFLOPs: 647.6686
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #5: GFLOPs: 1618.7215. Time: 6.7884 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #6: GFLOPs: 177.8857. Time: 61.7731 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #7: GFLOPs: 1454.6634. Time: 7.5540 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #8: GFLOPs: 1130.0095. Time: 9.7243 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #9: GFLOPs: 1351.2661. Time: 8.1320 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #10: GFLOPs: 121.7985. Time: 90.2190 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #11: GFLOPs: 877.5950. Time: 12.5212 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #12: GFLOPs: 1180.4193. Time: 9.3090 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #13: GFLOPs: 759.1037. Time: 14.4757 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #14: GFLOPs: 705.2580. Time: 15.5809 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #15: GFLOPs: 905.8428. Time: 12.1307 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #16: GFLOPs: 561.1148. Time: 19.5834 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #17: GFLOPs: 1226.4687. Time: 8.9595 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #18: GFLOPs: 650.0895. Time: 16.9031 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #19: GFLOPs: 413.3774. Time: 26.5824 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #20: GFLOPs: 102.7863. Time: 106.9067 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #21: GFLOPs: 690.3097. Time: 15.9183 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #22: GFLOPs: 553.0936. Time: 19.8674 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #23: GFLOPs: 14.4745. Time: 759.1674 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #24: GFLOPs: 867.1389. Time: 12.6722 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #25: GFLOPs: 861.0322. Time: 12.7621 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #26: GFLOPs: 69.3809. Time: 158.3800 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #27: GFLOPs: 1080.9130. Time: 10.1660 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #28: GFLOPs: 385.4022. Time: 28.5119 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #29: GFLOPs: 221.5080. Time: 49.6079 us. Best GFLOPs: 1618.7215
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #30: GFLOPs: 2060.2316. Time: 5.3336 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #31: GFLOPs: 535.4263. Time: 20.5230 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #32: GFLOPs: 1848.3572. Time: 5.9450 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #33: GFLOPs: 352.9646. Time: 31.1321 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #34: GFLOPs: 852.9073. Time: 12.8836 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #35: GFLOPs: 69.2751. Time: 158.6218 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #36: GFLOPs: 785.7896. Time: 13.9841 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #37: GFLOPs: 1827.0526. Time: 6.0144 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #38: GFLOPs: 771.9291. Time: 14.2352 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #39: GFLOPs: 1349.0387. Time: 8.1455 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #40: GFLOPs: 563.7791. Time: 19.4909 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #41: GFLOPs: 90.2614. Time: 121.7413 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #42: GFLOPs: 881.9521. Time: 12.4593 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #43: GFLOPs: 1665.9631. Time: 6.5959 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #44: GFLOPs: 74.8261. Time: 146.8545 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #45: GFLOPs: 813.3073. Time: 13.5109 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #46: GFLOPs: 38.9824. Time: 281.8847 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #47: GFLOPs: 155.4220. Time: 70.7013 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #48: GFLOPs: 1859.2351. Time: 5.9103 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #49: GFLOPs: 643.4847. Time: 17.0766 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #50: GFLOPs: 650.9547. Time: 16.8807 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #51: GFLOPs: 494.8292. Time: 22.2067 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #52: GFLOPs: 123.4635. Time: 89.0024 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #53: GFLOPs: 357.3009. Time: 30.7543 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #54: GFLOPs: 1571.4381. Time: 6.9927 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #55: GFLOPs: 719.4357. Time: 15.2738 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #56: GFLOPs: 466.4186. Time: 23.5594 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #57: GFLOPs: 1456.4543. Time: 7.5447 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #58: GFLOPs: 1152.4633. Time: 9.5348 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #59: GFLOPs: 1154.5770. Time: 9.5174 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #60: GFLOPs: 297.4784. Time: 36.9390 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #61: GFLOPs: 1096.5130. Time: 10.0214 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #62: GFLOPs: 722.8575. Time: 15.2015 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #63: GFLOPs: 1280.6699. Time: 8.5803 us. Best GFLOPs: 2060.2316
2024-03-21 20:21:51 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #64: GFLOPs: 355.9759. Time: 30.8688 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:03 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-03-21 20:38:04 [INFO] [evolutionary_search.cc:715] Picked top 64 candidate(s) from database
2024-03-21 20:38:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 427 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 20:38:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 851 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 20:38:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 1276 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 20:38:06 [INFO] [evolutionary_search.cc:723] Sampled 68 candidate(s)
2024-03-21 20:38:07 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 75 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 20:38:10 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 90 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 20:38:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 99 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 20:38:14 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 79 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 20:38:16 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9782  0.9690  0.9594  0.9538  0.9447  0.9408  0.9342  0.9333  0.9331  0.9326  0.9318  0.9316  0.9306  0.9270  0.9255  0.9253
[17 : 32]:	0.9251  0.9238  0.9225  0.9199  0.9190  0.9181  0.9165  0.9160  0.9156  0.9146  0.9118  0.9100  0.9065  0.9064  0.9038  0.9032
[33 : 48]:	0.9013  0.8978  0.8973  0.8971  0.8967  0.8962  0.8962  0.8961  0.8935  0.8916  0.8912  0.8906  0.8891  0.8880  0.8858  0.8832
[49 : 64]:	0.8807  0.8807  0.8793  0.8791  0.8785  0.8758  0.8756  0.8755  0.8740  0.8735  0.8729  0.8727  0.8700  0.8699  0.8672  0.8646
2024-03-21 20:38:16 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-03-21 20:38:16 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #65: GFLOPs: 1821.6299. Time: 6.0323 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #66: GFLOPs: 1958.4024. Time: 5.6110 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #67: GFLOPs: 1846.7228. Time: 5.9503 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #68: GFLOPs: 1936.1586. Time: 5.6754 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #69: GFLOPs: 1858.7820. Time: 5.9117 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #70: GFLOPs: 1686.1141. Time: 6.5171 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #71: GFLOPs: 1953.5297. Time: 5.6250 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #72: GFLOPs: 1892.4267. Time: 5.8066 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #73: GFLOPs: 1904.7243. Time: 5.7691 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #74: GFLOPs: 1888.0153. Time: 5.8202 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #75: GFLOPs: 1894.7811. Time: 5.7994 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #76: GFLOPs: 1797.9578. Time: 6.1117 us. Best GFLOPs: 2060.2316
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #77: GFLOPs: 2090.3403. Time: 5.2568 us. Best GFLOPs: 2090.3403
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #78: GFLOPs: 1945.3979. Time: 5.6485 us. Best GFLOPs: 2090.3403
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #79: GFLOPs: 2623.6834. Time: 4.1882 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #80: GFLOPs: 1932.6140. Time: 5.6858 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #81: GFLOPs: 2165.0589. Time: 5.0754 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #82: GFLOPs: 1924.7297. Time: 5.7091 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #83: GFLOPs: 2102.4835. Time: 5.2265 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #84: GFLOPs: 2589.3674. Time: 4.2437 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #85: GFLOPs: 2113.7551. Time: 5.1986 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #86: GFLOPs: 1832.0089. Time: 5.9981 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #87: GFLOPs: 1988.6304. Time: 5.5257 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #88: GFLOPs: 2134.3807. Time: 5.1484 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #89: GFLOPs: 1757.8909. Time: 6.2510 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #90: GFLOPs: 2189.3742. Time: 5.0190 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #91: GFLOPs: 1926.3115. Time: 5.7044 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #92: GFLOPs: 1757.6229. Time: 6.2519 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #93: GFLOPs: 1849.1498. Time: 5.9425 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #94: GFLOPs: 2306.1112. Time: 4.7650 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #95: GFLOPs: 2104.7880. Time: 5.2207 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #96: GFLOPs: 1665.7683. Time: 6.5967 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #97: GFLOPs: 1822.6398. Time: 6.0289 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #98: GFLOPs: 1889.7524. Time: 5.8148 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #99: GFLOPs: 1523.7663. Time: 7.2114 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #100: GFLOPs: 2031.1579. Time: 5.4100 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #101: GFLOPs: 1675.5627. Time: 6.5581 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #102: GFLOPs: 1926.5431. Time: 5.7038 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #103: GFLOPs: 1926.5276. Time: 5.7038 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #104: GFLOPs: 1800.7028. Time: 6.1024 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #105: GFLOPs: 1963.6424. Time: 5.5960 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #106: GFLOPs: 2131.0881. Time: 5.1563 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #107: GFLOPs: 2070.3616. Time: 5.3075 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #108: GFLOPs: 2386.7321. Time: 4.6040 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #109: GFLOPs: 1145.6835. Time: 9.5913 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #110: GFLOPs: 1807.3032. Time: 6.0801 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #111: GFLOPs: 2622.3037. Time: 4.1904 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #112: GFLOPs: 1877.9001. Time: 5.8515 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #113: GFLOPs: 1386.0510. Time: 7.9280 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #114: GFLOPs: 1791.2773. Time: 6.1345 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #115: GFLOPs: 2608.0748. Time: 4.2133 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #116: GFLOPs: 2068.6990. Time: 5.3118 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #117: GFLOPs: 2062.5443. Time: 5.3277 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #118: GFLOPs: 1897.9019. Time: 5.7898 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #119: GFLOPs: 2014.6406. Time: 5.4543 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #120: GFLOPs: 1889.9153. Time: 5.8143 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #121: GFLOPs: 1788.6235. Time: 6.1436 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #122: GFLOPs: 2067.9924. Time: 5.3136 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #123: GFLOPs: 2221.0559. Time: 4.9474 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #124: GFLOPs: 2450.3236. Time: 4.4845 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #125: GFLOPs: 1836.4293. Time: 5.9836 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #126: GFLOPs: 522.9108. Time: 21.0142 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #127: GFLOPs: 748.9697. Time: 14.6715 us. Best GFLOPs: 2623.6834
2024-03-21 20:38:59 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #128: GFLOPs: 120.3651. Time: 91.2934 us. Best GFLOPs: 2623.6834
2024-03-21 21:14:42 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-03-21 21:14:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-03-21 21:14:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 386 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:14:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 783 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:14:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 1169 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:14:44 [INFO] [evolutionary_search.cc:723] Sampled 61 candidate(s)
2024-03-21 21:14:46 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 89 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:14:48 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 86 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:14:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 79 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:14:53 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 83 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:14:54 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9793  0.9737  0.9729  0.9638  0.9627  0.9612  0.9604  0.9539  0.9518  0.9507  0.9491  0.9491  0.9486  0.9474  0.9463  0.9453
[17 : 32]:	0.9442  0.9426  0.9399  0.9391  0.9385  0.9341  0.9340  0.9338  0.9333  0.9324  0.9311  0.9304  0.9288  0.9288  0.9283  0.9264
[33 : 48]:	0.9247  0.9180  0.9168  0.9158  0.9143  0.9060  0.9040  0.9012  0.9000  0.8981  0.8947  0.8940  0.8937  0.8921  0.8918  0.8898
[49 : 64]:	0.8898  0.8891  0.8890  0.8883  0.8883  0.8879  0.8858  0.8856  0.8843  0.8810  0.8771  0.8762  0.8758  0.8750  0.8748  0.8741
2024-03-21 21:14:55 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-03-21 21:14:55 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #129: GFLOPs: 2524.9270. Time: 4.3520 us. Best GFLOPs: 2623.6834
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #130: GFLOPs: 2609.8576. Time: 4.2104 us. Best GFLOPs: 2623.6834
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #131: GFLOPs: 2624.3938. Time: 4.1871 us. Best GFLOPs: 2624.3938
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #132: GFLOPs: 2631.7842. Time: 4.1753 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #133: GFLOPs: 2624.8369. Time: 4.1864 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #134: GFLOPs: 2623.2513. Time: 4.1889 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #135: GFLOPs: 2628.5214. Time: 4.1805 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #136: GFLOPs: 2591.9850. Time: 4.2394 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #137: GFLOPs: 2561.5687. Time: 4.2898 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #138: GFLOPs: 2467.4743. Time: 4.4534 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #139: GFLOPs: 2481.0593. Time: 4.4290 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #140: GFLOPs: 2453.5459. Time: 4.4786 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #141: GFLOPs: 2551.4692. Time: 4.3068 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #142: GFLOPs: 2409.0493. Time: 4.5614 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #143: GFLOPs: 2550.3191. Time: 4.3087 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #144: GFLOPs: 2538.7245. Time: 4.3284 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #145: GFLOPs: 2472.7446. Time: 4.4439 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #146: GFLOPs: 2520.0578. Time: 4.3604 us. Best GFLOPs: 2631.7842
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #147: GFLOPs: 2633.2237. Time: 4.1730 us. Best GFLOPs: 2633.2237
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #148: GFLOPs: 2499.3426. Time: 4.3966 us. Best GFLOPs: 2633.2237
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #149: GFLOPs: 2556.3272. Time: 4.2986 us. Best GFLOPs: 2633.2237
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #150: GFLOPs: 2234.1272. Time: 4.9185 us. Best GFLOPs: 2633.2237
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #151: GFLOPs: 2542.2881. Time: 4.3223 us. Best GFLOPs: 2633.2237
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #152: GFLOPs: 2575.4609. Time: 4.2666 us. Best GFLOPs: 2633.2237
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #153: GFLOPs: 2634.4893. Time: 4.1710 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #154: GFLOPs: 2466.3369. Time: 4.4554 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #155: GFLOPs: 2572.7750. Time: 4.2711 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #156: GFLOPs: 2434.6689. Time: 4.5134 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #157: GFLOPs: 2577.7174. Time: 4.2629 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #158: GFLOPs: 2383.8307. Time: 4.6096 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #159: GFLOPs: 2386.6830. Time: 4.6041 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #160: GFLOPs: 2370.0374. Time: 4.6364 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #161: GFLOPs: 2251.6149. Time: 4.8803 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #162: GFLOPs: 2465.8620. Time: 4.4563 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #163: GFLOPs: 2394.4897. Time: 4.5891 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #164: GFLOPs: 2632.2428. Time: 4.1746 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #165: GFLOPs: 2629.6578. Time: 4.1787 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #166: GFLOPs: 2448.8955. Time: 4.4871 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #167: GFLOPs: 2076.7438. Time: 5.2912 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #168: GFLOPs: 2457.8066. Time: 4.4709 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #169: GFLOPs: 2228.9500. Time: 4.9299 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #170: GFLOPs: 1973.4570. Time: 5.5682 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #171: GFLOPs: 2458.2104. Time: 4.4701 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #172: GFLOPs: 2633.7486. Time: 4.1722 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #173: GFLOPs: 2387.7910. Time: 4.6020 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #174: GFLOPs: 2212.4523. Time: 4.9667 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #175: GFLOPs: 2517.1638. Time: 4.3654 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #176: GFLOPs: 2322.0619. Time: 4.7322 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #177: GFLOPs: 2461.9350. Time: 4.4634 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #178: GFLOPs: 2216.1098. Time: 4.9585 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #179: GFLOPs: 2190.9525. Time: 5.0154 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #180: GFLOPs: 2149.2195. Time: 5.1128 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #181: GFLOPs: 2185.2315. Time: 5.0285 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #182: GFLOPs: 2041.4506. Time: 5.3827 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #183: GFLOPs: 2256.5958. Time: 4.8695 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #184: GFLOPs: 2544.7710. Time: 4.3181 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #185: GFLOPs: 2394.5846. Time: 4.5889 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #186: GFLOPs: 2364.2421. Time: 4.6478 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #187: GFLOPs: 1923.8144. Time: 5.7119 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #188: GFLOPs: 2512.7306. Time: 4.3731 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #189: GFLOPs: 2193.3900. Time: 5.0098 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #190: GFLOPs: 852.2683. Time: 12.8933 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #191: GFLOPs: 804.6028. Time: 13.6571 us. Best GFLOPs: 2634.4893
2024-03-21 21:15:35 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #192: GFLOPs: 1463.7362. Time: 7.5072 us. Best GFLOPs: 2634.4893
2024-03-21 21:43:48 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-03-21 21:43:48 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-03-21 21:43:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 394 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:43:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 786 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:43:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 1183 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:43:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 1574 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:43:50 [INFO] [evolutionary_search.cc:723] Sampled 66 candidate(s)
2024-03-21 21:43:52 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 63 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:43:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 57 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:43:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 64 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:43:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 52 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 21:44:00 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0062  1.0006  0.9949  0.9947  0.9939  0.9930  0.9910  0.9888  0.9876  0.9873  0.9871  0.9866  0.9853  0.9846  0.9826  0.9821
[17 : 32]:	0.9817  0.9815  0.9777  0.9776  0.9767  0.9763  0.9755  0.9740  0.9735  0.9732  0.9727  0.9723  0.9714  0.9709  0.9706  0.9669
[33 : 48]:	0.9665  0.9650  0.9649  0.9641  0.9634  0.9628  0.9623  0.9606  0.9606  0.9601  0.9598  0.9590  0.9590  0.9590  0.9584  0.9578
[49 : 64]:	0.9574  0.9573  0.9558  0.9557  0.9545  0.9541  0.9537  0.9534  0.9531  0.9513  0.9512  0.9512  0.9512  0.9507  0.9487  0.9485
2024-03-21 21:44:00 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-03-21 21:44:00 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #193: GFLOPs: 2655.0128. Time: 4.1388 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #194: GFLOPs: 2459.3411. Time: 4.4681 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #195: GFLOPs: 2627.8813. Time: 4.1815 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #196: GFLOPs: 2552.3458. Time: 4.3053 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #197: GFLOPs: 2631.1977. Time: 4.1763 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #198: GFLOPs: 2499.7402. Time: 4.3959 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #199: GFLOPs: 2634.5835. Time: 4.1709 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #200: GFLOPs: 2489.8335. Time: 4.4134 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #201: GFLOPs: 2604.7999. Time: 4.2186 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #202: GFLOPs: 2394.8310. Time: 4.5884 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #203: GFLOPs: 2623.3178. Time: 4.1888 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #204: GFLOPs: 2634.1202. Time: 4.1716 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #205: GFLOPs: 2626.7514. Time: 4.1833 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #206: GFLOPs: 2540.3950. Time: 4.3255 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #207: GFLOPs: 2581.5671. Time: 4.2565 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #208: GFLOPs: 2617.2065. Time: 4.1986 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #209: GFLOPs: 2635.1824. Time: 4.1699 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #210: GFLOPs: 2479.5996. Time: 4.4316 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #211: GFLOPs: 2458.2144. Time: 4.4701 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #212: GFLOPs: 2325.9606. Time: 4.7243 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #213: GFLOPs: 2582.3006. Time: 4.2553 us. Best GFLOPs: 2655.0128
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #214: GFLOPs: 2675.4807. Time: 4.1071 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #215: GFLOPs: 2642.2398. Time: 4.1588 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #216: GFLOPs: 2596.0003. Time: 4.2329 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #217: GFLOPs: 2494.5284. Time: 4.4051 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #218: GFLOPs: 2385.7694. Time: 4.6059 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #219: GFLOPs: 2551.7638. Time: 4.3063 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #220: GFLOPs: 2581.6543. Time: 4.2564 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #221: GFLOPs: 2584.9030. Time: 4.2510 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #222: GFLOPs: 2552.4278. Time: 4.3051 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #223: GFLOPs: 2600.2569. Time: 4.2259 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #224: GFLOPs: 2614.0167. Time: 4.2037 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #225: GFLOPs: 2548.2953. Time: 4.3121 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #226: GFLOPs: 2518.7961. Time: 4.3626 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #227: GFLOPs: 2616.2401. Time: 4.2001 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #228: GFLOPs: 2530.7593. Time: 4.3420 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #229: GFLOPs: 2608.7441. Time: 4.2122 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #230: GFLOPs: 2626.2861. Time: 4.1841 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #231: GFLOPs: 2608.5086. Time: 4.2126 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #232: GFLOPs: 2485.6996. Time: 4.4207 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #233: GFLOPs: 2539.1374. Time: 4.3277 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #234: GFLOPs: 2438.1601. Time: 4.5069 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #235: GFLOPs: 2440.7583. Time: 4.5021 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #236: GFLOPs: 2614.1063. Time: 4.2036 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #237: GFLOPs: 2613.9413. Time: 4.2038 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #238: GFLOPs: 2452.0060. Time: 4.4815 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #239: GFLOPs: 2458.1726. Time: 4.4702 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #240: GFLOPs: 2495.3982. Time: 4.4035 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #241: GFLOPs: 2487.1676. Time: 4.4181 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #242: GFLOPs: 2589.4999. Time: 4.2435 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #243: GFLOPs: 2537.4180. Time: 4.3306 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #244: GFLOPs: 2525.0213. Time: 4.3519 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #245: GFLOPs: 2495.2979. Time: 4.4037 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #246: GFLOPs: 2458.9938. Time: 4.4687 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #247: GFLOPs: 2570.9055. Time: 4.2742 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #248: GFLOPs: 2606.2426. Time: 4.2162 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #249: GFLOPs: 2658.4106. Time: 4.1335 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #250: GFLOPs: 2564.5958. Time: 4.2847 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #251: GFLOPs: 2619.5637. Time: 4.1948 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #252: GFLOPs: 2527.3297. Time: 4.3479 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #253: GFLOPs: 2452.2472. Time: 4.4810 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #254: GFLOPs: 168.6369. Time: 65.1610 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #255: GFLOPs: 718.7830. Time: 15.2877 us. Best GFLOPs: 2675.4807
2024-03-21 21:44:42 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #256: GFLOPs: 295.3396. Time: 37.2065 us. Best GFLOPs: 2675.4807
2024-03-21 22:07:09 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-03-21 22:07:09 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-03-21 22:07:10 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 391 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 22:07:10 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 785 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 22:07:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 1180 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 22:07:11 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2024-03-21 22:07:12 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 56 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 22:07:14 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 46 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 22:07:16 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 48 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 22:07:19 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x6521ebd424a8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x6521ed7c6e68)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x6521ed7cfa38)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x6521ed730f08)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x6521ebde1db8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x6521ed7d5bd8)]: 60 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x6521ed7c4e38)]: 0 failure(s)
2024-03-21 22:07:20 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0551  1.0059  1.0057  0.9976  0.9969  0.9921  0.9919  0.9912  0.9903  0.9886  0.9882  0.9874  0.9862  0.9860  0.9853  0.9853
[17 : 32]:	0.9849  0.9837  0.9834  0.9828  0.9828  0.9821  0.9813  0.9812  0.9807  0.9802  0.9796  0.9795  0.9795  0.9793  0.9788  0.9784
[33 : 48]:	0.9783  0.9783  0.9781  0.9780  0.9774  0.9772  0.9763  0.9763  0.9763  0.9759  0.9759  0.9759  0.9754  0.9754  0.9753  0.9751
[49 : 64]:	0.9751  0.9750  0.9747  0.9738  0.9738  0.9731  0.9730  0.9730  0.9729  0.9720  0.9720  0.9718  0.9718  0.9718  0.9717  0.9717
2024-03-21 22:07:20 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-03-21 22:07:20 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #257: GFLOPs: 2326.1354. Time: 4.7239 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #258: GFLOPs: 2339.5389. Time: 4.6969 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #259: GFLOPs: 2570.3389. Time: 4.2751 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #260: GFLOPs: 2339.3078. Time: 4.6973 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #261: GFLOPs: 2475.5391. Time: 4.4388 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #262: GFLOPs: 2474.3096. Time: 4.4411 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #263: GFLOPs: 2654.6595. Time: 4.1393 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #264: GFLOPs: 2408.5870. Time: 4.5622 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #265: GFLOPs: 2654.6033. Time: 4.1394 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #266: GFLOPs: 2485.8556. Time: 4.4204 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #267: GFLOPs: 2647.8070. Time: 4.1501 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #268: GFLOPs: 2655.2147. Time: 4.1385 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #269: GFLOPs: 2633.6381. Time: 4.1724 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #270: GFLOPs: 2588.2503. Time: 4.2455 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #271: GFLOPs: 2633.0057. Time: 4.1734 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #272: GFLOPs: 2606.5198. Time: 4.2158 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #273: GFLOPs: 2561.1045. Time: 4.2905 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #274: GFLOPs: 2618.1749. Time: 4.1970 us. Best GFLOPs: 2675.4807
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #275: GFLOPs: 2722.7024. Time: 4.0359 us. Best GFLOPs: 2722.7024
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #276: GFLOPs: 2635.0351. Time: 4.1702 us. Best GFLOPs: 2722.7024
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #277: GFLOPs: 2634.9353. Time: 4.1703 us. Best GFLOPs: 2722.7024
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #278: GFLOPs: 2602.9987. Time: 4.2215 us. Best GFLOPs: 2722.7024
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #279: GFLOPs: 2769.2550. Time: 3.9681 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #280: GFLOPs: 2632.7222. Time: 4.1738 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #281: GFLOPs: 2633.7036. Time: 4.1723 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #282: GFLOPs: 2631.4856. Time: 4.1758 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #283: GFLOPs: 2635.0932. Time: 4.1701 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #284: GFLOPs: 2635.5375. Time: 4.1694 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #285: GFLOPs: 2622.0183. Time: 4.1909 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #286: GFLOPs: 2600.1023. Time: 4.2262 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #287: GFLOPs: 2607.0287. Time: 4.2150 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #288: GFLOPs: 2602.3278. Time: 4.2226 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #289: GFLOPs: 2616.7799. Time: 4.1993 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #290: GFLOPs: 2625.4657. Time: 4.1854 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #291: GFLOPs: 2587.2656. Time: 4.2472 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #292: GFLOPs: 2599.6572. Time: 4.2269 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #293: GFLOPs: 2560.0410. Time: 4.2923 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #294: GFLOPs: 2634.9659. Time: 4.1703 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #295: GFLOPs: 2686.7685. Time: 4.0899 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #296: GFLOPs: 2687.0841. Time: 4.0894 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #297: GFLOPs: 2686.1925. Time: 4.0908 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #298: GFLOPs: 2517.9720. Time: 4.3640 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #299: GFLOPs: 2634.1632. Time: 4.1716 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #300: GFLOPs: 2635.1363. Time: 4.1700 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #301: GFLOPs: 2619.7713. Time: 4.1945 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #302: GFLOPs: 2618.8435. Time: 4.1960 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #303: GFLOPs: 2631.6980. Time: 4.1755 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #304: GFLOPs: 2590.2534. Time: 4.2423 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #305: GFLOPs: 2633.8962. Time: 4.1720 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #306: GFLOPs: 2632.9213. Time: 4.1735 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #307: GFLOPs: 2606.7976. Time: 4.2153 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #308: GFLOPs: 2635.2316. Time: 4.1699 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #309: GFLOPs: 2630.5222. Time: 4.1773 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #310: GFLOPs: 2620.4407. Time: 4.1934 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #311: GFLOPs: 2553.5613. Time: 4.3032 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #312: GFLOPs: 2474.6780. Time: 4.4404 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #313: GFLOPs: 2597.0230. Time: 4.2312 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #314: GFLOPs: 2623.5761. Time: 4.1884 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #315: GFLOPs: 2563.2538. Time: 4.2870 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #316: GFLOPs: 2630.1305. Time: 4.1779 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #317: GFLOPs: 2627.7889. Time: 4.1817 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #318: GFLOPs: 1108.2119. Time: 9.9156 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #319: GFLOPs: 456.6125. Time: 24.0654 us. Best GFLOPs: 2769.2550
2024-03-21 22:08:03 [INFO] [task_scheduler.cc:131] [Task #7: fused_nn_conv2d_add_add] Trial #320: GFLOPs: 262.3490. Time: 41.8852 us. Best GFLOPs: 2769.2550
